{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1.2 - Линейный классификатор (Linear classifier)\n",
    "\n",
    "В этом задании мы реализуем другую модель машинного обучения - линейный классификатор. Линейный классификатор подбирает для каждого класса веса, на которые нужно умножить значение каждого признака и потом сложить вместе.\n",
    "Тот класс, у которого эта сумма больше, и является предсказанием модели.\n",
    "\n",
    "В этом задании вы:\n",
    "- потренируетесь считать градиенты различных многомерных функций\n",
    "- реализуете подсчет градиентов через линейную модель и функцию потерь softmax\n",
    "- реализуете процесс тренировки линейного классификатора\n",
    "- подберете параметры тренировки на практике\n",
    "\n",
    "На всякий случай, еще раз ссылка на туториал по numpy:  \n",
    "http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_gradient\n",
    "from metrics import multiclass_accuracy \n",
    "import linear_classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, первым делом загружаем данные\n",
    "\n",
    "Мы будем использовать все тот же SVHN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_linear_classifier(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float32) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float32) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    # Add another channel with ones as a bias term\n",
    "    train_flat_with_ones = np.hstack([train_flat, np.ones((train_X.shape[0], 1))])\n",
    "    test_flat_with_ones = np.hstack([test_flat, np.ones((test_X.shape[0], 1))])    \n",
    "    return train_flat_with_ones, test_flat_with_ones\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_linear_classifier(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Играемся с градиентами!\n",
    "\n",
    "В этом курсе мы будем писать много функций, которые вычисляют градиенты аналитическим методом.\n",
    "\n",
    "Все функции, в которых мы будем вычислять градиенты, будут написаны по одной и той же схеме.  \n",
    "Они будут получать на вход точку, где нужно вычислить значение и градиент функции, а на выходе будут выдавать кортеж (tuple) из двух значений - собственно значения функции в этой точке (всегда одно число) и аналитического значения градиента в той же точке (той же размерности, что и вход).\n",
    "```\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    Computes function and analytic gradient at x\n",
    "    \n",
    "    x: np array of float, input to the function\n",
    "    \n",
    "    Returns:\n",
    "    value: float, value of the function \n",
    "    grad: np array of float, same shape as x\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \n",
    "    return value, grad\n",
    "```\n",
    "\n",
    "Необходимым инструментом во время реализации кода, вычисляющего градиенты, является функция его проверки. Эта функция вычисляет градиент численным методом и сверяет результат с градиентом, вычисленным аналитическим методом.\n",
    "\n",
    "Мы начнем с того, чтобы реализовать вычисление численного градиента (numeric gradient) в функции `check_gradient` в `gradient_check.py`. Эта функция будет принимать на вход функции формата, заданного выше, использовать значение `value` для вычисления численного градиента и сравнит его с аналитическим - они должны сходиться.\n",
    "\n",
    "Напишите часть функции, которая вычисляет градиент с помощью численной производной для каждой координаты. Для вычисления производной используйте так называемую two-point formula (https://en.wikipedia.org/wiki/Numerical_differentiation):\n",
    "\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/22fc2c0a66c63560a349604f8b6b39221566236d)\n",
    "\n",
    "Все функции приведенные в следующей клетке должны проходить gradient check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check completed!\n",
      "Gradient check completed!\n",
      "Gradient check completed!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test gradient check\n",
    "\n",
    "def square(x):\n",
    "    return float(x * x), 2 * x\n",
    "\n",
    "check_gradient(square, np.array([3.0]))\n",
    "\n",
    "def array_sum(x):\n",
    "    assert x.shape == (2, ) , x.shape\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_sum, np.array([3.0, 2.0]))\n",
    "\n",
    "def array_2d_sum(x):\n",
    "    assert x.shape == (2,2)\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_2d_sum, np.array([[3.0, 2.0], [1.0, 0.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Начинаем писать свои функции, считающие аналитический градиент\n",
    "\n",
    "Теперь реализуем функцию softmax, которая получает на вход оценки для каждого класса и преобразует их в вероятности от 0 до 1:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3)\n",
    "\n",
    "**Важно:** Практический аспект вычисления этой функции заключается в том, что в ней учавствует вычисление экспоненты от потенциально очень больших чисел - это может привести к очень большим значениям в числителе и знаменателе за пределами диапазона float.\n",
    "\n",
    "К счастью, у этой проблемы есть простое решение -- перед вычислением softmax вычесть из всех оценок максимальное значение среди всех оценок:\n",
    "```\n",
    "predictions -= np.max(predictions)\n",
    "```\n",
    "(подробнее здесь - http://cs231n.github.io/linear-classify/#softmax, секция `Practical issues: Numeric stability`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Implement softmax and cross-entropy for single sample\n",
    "probs = linear_classifer.softmax(np.array([-10, 0, 10]))\n",
    "\n",
    "# Make sure it works for big numbers too!\n",
    "probs = linear_classifer.softmax(np.array([1000, 0, 0]))\n",
    "assert np.isclose(probs[0], 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме этого, мы реализуем cross-entropy loss, которую мы будем использовать как функцию ошибки (error function).\n",
    "В общем виде cross-entropy определена следующим образом:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/0cb6da032ab424eefdca0884cd4113fe578f4293)\n",
    "\n",
    "где x - все классы, p(x) - истинная вероятность принадлежности сэмпла классу x, а q(x) - вероятность принадлежности классу x, предсказанная моделью.  \n",
    "В нашем случае сэмпл принадлежит только одному классу, индекс которого передается функции. Для него p(x) равна 1, а для остальных классов - 0. \n",
    "\n",
    "Это позволяет реализовать функцию проще!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "5.006760443547122"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = linear_classifer.softmax(np.array([-5, 0, 5]))\n",
    "linear_classifer.cross_entropy_loss(probs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того как мы реализовали сами функции, мы можем реализовать градиент.\n",
    "\n",
    "Оказывается, что вычисление градиента становится гораздо проще, если объединить эти функции в одну, которая сначала вычисляет вероятности через softmax, а потом использует их для вычисления функции ошибки через cross-entropy loss.\n",
    "\n",
    "Эта функция `softmax_with_cross_entropy` будет возвращает и значение ошибки, и градиент по входным параметрам. Мы проверим корректность реализации с помощью `check_gradient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check completed!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement combined function or softmax and cross entropy and produces gradient\n",
    "loss, grad = linear_classifer.softmax_with_cross_entropy(np.array([1, 0, 0]), 1)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, 1), np.array([1, 0, 0], float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метода тренировки мы будем использовать стохастический градиентный спуск (stochastic gradient descent или SGD), который работает с батчами сэмплов. \n",
    "\n",
    "Поэтому все наши фукнции будут получать не один пример, а батч, то есть входом будет не вектор из `num_classes` оценок, а матрица размерности `batch_size, num_classes`. Индекс примера в батче всегда будет первым измерением.\n",
    "\n",
    "Следующий шаг - переписать наши функции так, чтобы они поддерживали батчи.\n",
    "\n",
    "Финальное значение функции ошибки должно остаться числом, и оно равно среднему значению ошибки среди всех примеров в батче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO Extend combined function so it can receive a 2d array with batch of samples\n",
    "np.random.seed(42)\n",
    "# Test batch_size = 1\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test batch_size = 3\n",
    "batch_size = 3\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(float)\n",
    "target_index = np.random.randint(0, num_classes, size=batch_size).astype(int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# Make sure maximum subtraction for numberic stability is done separately for every sample in the batch\n",
    "probs = linear_classifer.softmax(np.array([[20,0,0], [1000, 0, 0]]))\n",
    "assert np.all(np.isclose(probs[:, 0], 1.0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наконец, реализуем сам линейный классификатор!\n",
    "\n",
    "softmax и cross-entropy получают на вход оценки, которые выдает линейный классификатор.\n",
    "\n",
    "Он делает это очень просто: для каждого класса есть набор весов, на которые надо умножить пиксели картинки и сложить. Получившееся число и является оценкой класса, идущей на вход softmax.\n",
    "\n",
    "Таким образом, линейный классификатор можно представить как умножение вектора с пикселями на матрицу W размера `num_features, num_classes`. Такой подход легко расширяется на случай батча векторов с пикселями X размера `batch_size, num_features`:\n",
    "\n",
    "`predictions = X * W`, где `*` - матричное умножение.\n",
    "\n",
    "Реализуйте функцию подсчета линейного классификатора и градиентов по весам `linear_softmax` в файле `linear_classifer.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_classes = 2\n",
    "num_features = 3\n",
    "np.random.seed(42)\n",
    "W = np.random.randint(-1, 3, size=(num_features, num_classes)).astype(float)\n",
    "X = np.random.randint(-1, 3, size=(batch_size, num_features)).astype(float)\n",
    "target_index = np.ones(batch_size, dtype=np.int32)\n",
    "\n",
    "loss, dW = linear_classifer.linear_softmax(X, W, target_index)\n",
    "check_gradient(lambda w: linear_classifer.linear_softmax(X, w, target_index), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### И теперь регуляризация\n",
    "\n",
    "Мы будем использовать L2 regularization для весов как часть общей функции ошибки.\n",
    "\n",
    "Напомним, L2 regularization определяется как\n",
    "\n",
    "l2_reg_loss = regularization_strength * sum<sub>ij</sub> W[i, j]<sup>2</sup>\n",
    "\n",
    "Реализуйте функцию для его вычисления и вычисления соотвествующих градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_classifer.l2_regularization(W, 0.01)\n",
    "check_gradient(lambda w: linear_classifer.l2_regularization(w, 0.01), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиенты в порядке, реализуем процесс тренировки!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:37<00:00,  2.68it/s]\n"
     ]
    }
   ],
   "source": [
    "classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "loss_history = classifier.fit(train_X, train_y, epochs=100, learning_rate=1e-3, batch_size=300, reg=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x23cab23fd48>]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD6CAYAAACvZ4z8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAim0lEQVR4nO3deXhd1Xnv8e97JskabEmWbDzLExgIBhxBAANJSUMCSRhCE9pwGUpbyE3bkF5ompCmTUqbljYhTR7acGlDCQlJmMwQQqAuZSiTY8kYz9h4lkfZkjUPZ3jvH2dLlmTJkjyJu8/v8zx+LO29js5a2uf8tM67J3N3REQkvCKj3QERETm+FPQiIiGnoBcRCTkFvYhIyCnoRURCTkEvIhJyQwa9mU0zs5fMbI2ZrTaz2w7T9hwzS5nZ7/RadqOZbQj+3XisOi4iIsNjQx1Hb2aTgEnuvszMioEa4Cp3X9OvXRRYDHQAD7j742ZWBlQDVYAHj/2guzcM9nzl5eVeWVl5FEMSEck9NTU1+9y9YqB1saEe7O67gF3B181mthaYAqzp1/RPgSeAc3ot+ziw2N3rAcxsMfAJ4OeDPV9lZSXV1dVDdUtERHoxs62DrRtRjd7MKoGzgSX9lk8BrgZ+2O8hU4Dtvb6vDZb1/7m3mFm1mVXX1dWNpEsiIjKEYQe9mRWRnbF/2d2b+q3+Z+Av3D1zJJ1w9/vdvcrdqyoqBvzkISIiR2jI0g2AmcXJhvzD7r5ogCZVwC/MDKAcuNzMUsAO4CO92k0FXj6K/oqIyAgNGfSWTe8fAWvd/Z6B2rj7zF7tHwSedfengp2x3zaz0mD1pcDXjrrXIiIybMOZ0S8ErgdWmtnyYNmdwHQAd79vsAe6e72Z3QUsDRb9TfeOWREROTGGc9TNa4AN9we6+039vn8AeGDEPRMRkWNCZ8aKiIRcaIK+tTPFPYvX8/a2Qc/FEhHJSaEJ+s5Uhh+8uIF3th8Y7a6IiLyvhCbo49HsboRURrdGFBHpLURBnx1KV/qIztkSEQmt0AV9MqUZvYhIb6EJ+mjEiBgkNaMXEekjNEEP2Vl9MqOgFxHpLVRBn4hGVLoREeknVEEfi5pKNyIi/YQq6OPRiIJeRKSfEAa9SjciIr2FKugTMc3oRUT6C1XQx1WjFxE5RKiCPhbRjF5EpL9QBX08FqFLNXoRkT5CFfSJqJHSjF5EpI9QBb0OrxQROVSogj4WVelGRKS/UAV9ImokU5rRi4j0Fqqgj0cjpHRRMxGRPkIX9DozVkSkr9AFfZdKNyIifYQs6HVmrIhIfyELeh1eKSLSX+iCPqUavYhIH+EK+pjRpRm9iEgf4Qp6XdRMROQQ4Qr6aISMQzqj8o2ISLdwBX3MADSrFxHpJVRBn4hmh6OgFxE5KFRBH4t0z+hVuhER6RaqoI/HNKMXEelvyKA3s2lm9pKZrTGz1WZ22wBtrjSzFWa23MyqzezCXuv+MXjcWjP7gZnZsR5Et3hQutFlEEREDooNo00KuN3dl5lZMVBjZovdfU2vNi8Cz7i7m9l84FFgnpldACwE5gftXgM+DLx8zEbQS3eNPqWjbkREegw5o3f3Xe6+LPi6GVgLTOnXpsXdu9O1EOj+2oF8IAHkAXFgz7Hp+qHi2hkrInKIEdXozawSOBtYMsC6q81sHfAr4GYAd38TeAnYFfx7wd3XDvDYW4KST3VdXd2IB9EtFs1WhVS6ERE5aNhBb2ZFwBPAl929qf96d3/S3ecBVwF3BY+ZA5wKTCX7KeASM7togMfe7+5V7l5VUVFxRAMBHV4pIjKQYQW9mcXJhvzD7r7ocG3d/VVglpmVA1cDbwWlnRbg18D5R9nnQcVVoxcROcRwjrox4EfAWne/Z5A2c7qPpjGzBWTr8fuBbcCHzSwW/LH4MNka/3ERD0o3um+siMhBwznqZiFwPbDSzJYHy+4EpgO4+33ANcANZpYE2oFrgyNwHgcuAVaS3TH7vLv/8tgO4aBY9+GVKt2IiPQYMujd/TXgsMe+u/vdwN0DLE8Dtx5x70boYI1epRsRkW4hOzM2+/copRm9iEiPcAW9SjciIocIVdCrdCMicqhQBX33CVM6jl5E5KBQBb0ugSAicqiQBr1KNyIi3UIV9LoEgojIoUIV9DGdGSsicohwBX1EO2NFRPoLVdCbGYlohKQuaiYi0iNUQQ/ZC5updCMiclDogj4Wjah0IyLSS+iCPh6N0KXDK0VEeoQu6BNR04xeRKSX0AV9PBbR1StFRHoJX9BHIzozVkSkl9AFfSxiukyxiEgvoQv6RExH3YiI9Ba6oI9HI6RUuhER6RHCoFfpRkSktxAGvUo3IiK9KehFREIuhEFvqtGLiPQSwqCPqEYvItJL6II+odKNiEgfoQv6WNRIplS6ERHpFrqg185YEZG+FPQiIiEXuqDPXgJBpRsRkW6hC/pYRNejFxHpLXRBH49GSGUcd83qRUQghEGfiGWHpPKNiEjWkEFvZtPM7CUzW2Nmq83stgHaXGlmK8xsuZlVm9mFvdZNN7P/NLO1wc+oPMZj6CMeNQCVb0REArFhtEkBt7v7MjMrBmrMbLG7r+nV5kXgGXd3M5sPPArMC9Y9BPyduy82syLguCZwLNI9o1fQi4jAMGb07r7L3ZcFXzcDa4Ep/dq0+MGieCHgAGZ2GhBz98W92rUdw/4fIh6UbnQZBBGRrBHV6IOyy9nAkgHWXW1m64BfATcHi08GDpjZIjN728z+ycyiAzz2lqDkU11XVzfiQfSW6CndqEYvIgIjCPqg7PIE8GV3b+q/3t2fdPd5wFXAXcHiGHARcAdwDjALuGmAx97v7lXuXlVRUTHSMfQRj2aHlNKMXkQEGGbQm1mcbMg/7O6LDtfW3V8FZplZOVALLHf3Te6eAp4CFhxdlw+vO+hVoxcRyRrOUTcG/AhY6+73DNJmTtAOM1sA5AH7gaVAiZl1T9MvAdYM9DOOle6jbrp0YTMREWB4R90sBK4HVprZ8mDZncB0AHe/D7gGuMHMkkA7cG2wczZtZncALwZ/CGqAfzu2Q+hLM3oRkb6GDHp3fw2wIdrcDdw9yLrFwPwj6t0R6KnRZxT0IiIQwjNju4NepRsRkawQBr3OjBUR6S2EQa8avYhIbwp6EZGQC13QJ2I6M1ZEpLfQBb0uaiYi0lfogj4eU9CLiPQWvqDvPjNWpRsRESCEQZ/QRc1ERPoIXdDrqBsRkb5CF/QxXY9eRKSP0AV9PNJ9CQTN6EVEIIRBH4kYsYjpomYiIoHQBT1k6/Qq3YiIZIUy6GNRU+lGRCQQyqBPRCM66kZEJBDKoI8r6EVEeoQz6GNGSjV6EREgrEEfjdClGb2ICBDWoI+odCMi0i2cQR8zHV4pIhIIZ9BrZ6yISA8FvYhIyIU06FW6ERHpFtKg14xeRKRbaINel0AQEckKZdAnohFSGZVuREQgpEEfi5pKNyIigVAGfTwaIanSjYgIEOKg79JRNyIiQEiDPhHVHaZERLqFMuhVuhEROWjIoDezaWb2kpmtMbPVZnbbAG2uNLMVZrbczKrN7MJ+68eaWa2Z3XssOz+YmG4lKCLSIzaMNingdndfZmbFQI2ZLXb3Nb3avAg84+5uZvOBR4F5vdbfBbx6zHo9hETU6EpncHfM7EQ9rYjI+9KQM3p33+Xuy4Kvm4G1wJR+bVrcvXsKXQj0TKfN7IPAROA/j1WnhxKPZoelY+lFREZYozezSuBsYMkA6642s3XAr4Cbg2UR4LvAHUP83FuCkk91XV3dSLo0oHgsCHqVb0REhh/0ZlYEPAF82d2b+q939yfdfR5wFdlSDcAXgefcvfZwP9vd73f3KnevqqioGHbnBxOLZMs1usuUiMjwavSYWZxsyD/s7osO19bdXzWzWWZWDpwPXGRmXwSKgISZtbj7V4+244eTCGb0OjtWRGQYQW/ZvZk/Ata6+z2DtJkDbAx2xi4A8oD97n5drzY3AVXHO+ThYI1eQS8iMrwZ/ULgemClmS0Plt0JTAdw9/uAa4AbzCwJtAPX9to5e8L17IxVjV5EZOigd/fXgMMeo+judwN3D9HmQeDBEfTtiMWjqtGLiHQL7ZmxoNKNiAiEPehTKt2IiIQ06LOlm6QubCYiEs6gT/TM6BX0IiKhDPpYT41epRsRkVAGfU/pRjtjRUTCGvTZYenwShGRkAZ9Qhc1ExHpEcqg776omUo3IiIhDXqVbkREDgpl0OvqlSIiB4Uy6HVRMxGRg0Ia9KrRi4h0C2nQq0YvItIt1EHfmVTQi4iEMuijEWNsfozG9uRod0VEZNSFMugBygoT1Ld2jXY3RERGXWiDvrQwQUObgl5EJLRBX1agGb2ICIQ46EsLEzQo6EVEwhv0ZYUJ6lW6EREJb9CXFiToSGZo70qPdldEREZVaIO+rDAOoFm9iOS80AZ9aUECQHV6Ecl5oQ36ssJs0OvIGxHJdaEN+tIg6HUsvYjkutAGfVmBZvQiIhDioB87Jk7EVKMXEQlt0EcjRkmBjqUXEQlt0AOUFsRpaNUVLEUkt4U66HUFSxGRkAd9aYGuYCkiEuqg14xeRGQYQW9m08zsJTNbY2arzey2AdpcaWYrzGy5mVWb2YXB8rPM7M3gcSvM7NrjMYjBdF+T3t1P5NOKiLyvxIbRJgXc7u7LzKwYqDGzxe6+plebF4Fn3N3NbD7wKDAPaANucPcNZjY5eOwL7n7gGI9jQGUFCZJpp6UzRXF+/EQ8pYjI+86QM3p33+Xuy4Kvm4G1wJR+bVr84LS5EPBg+Xp33xB8vRPYC1Qcu+4fXs/ZsTryRkRy2Ihq9GZWCZwNLBlg3dVmtg74FXDzAOvPBRLAxgHW3RKUfKrr6upG0qXD0hUsRURGEPRmVgQ8AXzZ3Zv6r3f3J919HnAVcFe/x04CfgL8vrtnBnjs/e5e5e5VFRXHbsJfVpgH6OxYEcltwwp6M4uTDfmH3X3R4dq6+6vALDMrDx47luws/+vu/tZR9ndEuq93s19BLyI5bDhH3RjwI2Ctu98zSJs5QTvMbAGQB+w3swTwJPCQuz9+7Lo9PKVB6UYzehHJZcM56mYhcD2w0syWB8vuBKYDuPt9wDXADWaWBNqBa4MjcD4HXAyMN7Obgsfe5O7LOQGK8mLEo6YavYjktCGD3t1fA2yINncDdw+w/KfAT4+4d0fJzLJnx2pGLyI5LNRnxoLOjhURCX3Q63o3IpLrQh/0mtGLSK4LfdCXFsZpaNOZsSKSu0If9GUFCQ60dZHO6MJmIpKbQh/0pYUJMg5N7ZrVi0huCn3QlwUXNtOx9CKSq0If9KUF3VewVNCLSG4KfdD3zOgV9CKSo0If9D3XpFfpRkRyVOiDvvsKlvW6+YiI5KjQB/2YRJT8eIR9LZ2j3RURkVER+qAHOHliMat3No52N0RERkVOBH3VjDKWbz9AV+qQm1uJiIReTgT9OZWldCQzmtWLSE7KiaD/YGUpANVbGka5JyIiJ15OBP2E4nwqxxewdEv9aHdFROSEy4mgB6iqLKN6awPuuriZiOSWnAn6cypLqW/tYtO+1tHuiojICZUzQV9VWQZAtco3IpJjciboZ5UXUlaYYKl2yIpIjsmZoDczqmaUakYvIjknZ4Ie4JzKMrbsb2Nvc8dod0VE5ITJqaCvCo6nr1H5RkRySE4F/emTx5Efj/D6xn2j3RURkRMmp4I+EYtw+RmTeGTpdjbWtYx2d0REToicCnqAr112KvnxKN94apVOnhKRnJBzQV9RnMdXPjGPNzbu55l3do52d+R96qV1e/nfP63h/lc3sqL2AKn0sbny6eM1tby3V58mw87deX7V7vfNgR85F/QAnz93OmdOK+GuZ9fQ2H5i7jyVyTirdjTS3pU+Ic/3/6uNdS3c8dg7bD7KM5ibO5J885nVPFq9fcSPXb2zkS8+vIxX1tfx7efWccW9r3Put1/kJ29tParAf/29fdzx2Dv8r39fwp6m4x8A7s5+3XDnhMtknG/9cg1f+GkNNz+4lM7U6L/n7f1WvqiqqvLq6urj/jyrdjRyxb2vMWdCER+YPI5pZQVcNLe85wxayL5RfvDie7y5aR93Xn4q86eWjPh5MhnnhdW7+f6LG1i3u5mK4jy+dMkcrj1nOonY8fs729qZYvO+VmaML6A4P37EP8fdeXPjfuqCwIiYceqkscyZUHRU/WtsS7KzsZ1TJ43tWdaRTHPFva+xfk8LxXkxvvO5M/n46Scd8tj39jbzwuo9zK4o5KK5FRTmxfqsX72zkT/52ds9fyz+8pOn8ocXzepZX9/aRdSMcQWH/l7qmju58t7XcODpP1mIOyzZXM/PlmzlrU31zDupmK9eNo8PzRzPmER02ON1d678l9fZ3dhBS2eKuROKeOTW88mPR3v6dKCti5KCBGPzY8SifV8bdc2dvPZeHQfakpw5rYTTJ48lLxalI5lmy/5W3Onzu8xknL9+ZjU/eWsrd14+j1sunj3svkL2D+63frmGU08q5rbfnktBou/vuLE9yZZ9rWzZ30pLZ4r8WJS8eIRkOsPuxk72NHVQUZzHLRfPIh4d+nXu7myrbwMgHo2QH49SMiZOJGJ92mUyzrJtDfx61W7+Z0MdVZVl/MXH5w24LYdr2/42Xnp3L12pDMlMhuK8GJefMYnxRXk9bVo6U6yoPcDY/DgVxXmUFSYGHFcqneGri1byeE0tl8ybwH+v28tNF1TyzStO7zMGB6L9xna0zKzG3asGXJerQQ/wi99sY9HbO6itb2NXMMP600vmcttH5+LufP3JVTxSvZ2CRPYNdcP5ldx+6clDBmcqnWH59gO8ur6OX6/azYa9LcwqL+S682bw/KpdLN3SwLSyMdxx6Sl8ev7knhdzJuP8Zks9RXkxTp88FrPs8j1NHTz4xhYa25NcMHs8C2eX99z0vP/zLtlczxPLanl+1W7agk8Pk8flM6uiiOL8GAWJGLGIsaupg9r6NhrauvjEB07iDy+axeyKvuG9vb6Nbzy9ipffrTvkueZOKOKyD5xEeXEeOxra2XGgnXFj4lw0t5zzZ5czbszAv6ONdS38x+ubeaJmB+3JdJ8Q/vqTK3l4yTb+4TNn8PPfbOOd2kZuXjiTs6aX4O40tSd5avlOarYePDw2EY1w/uzxzCwvpDg/RjLtPPD6ZkoL4tzzubN4eMlWnlu5m6984hSuOHMyP3x5I49V15KIRfjWFafzmQVTen7Pnak0n/+3Jaze2cjjX7iAD0wZ1/M83R/F//ZXa9lxoB0zmF5WwMkTizl7eglVM8qYP3VcT3D396sVu/jjny3jO589k7H5MW79aQ2fPGMSv79wJj9+YwvPrdxFKnPwvThuTJyTxuYzYWwe+1u6WLOrqc/PS8QilBcm2NXUQfdb+DNnT+EbnzqN4vwYf/74Cp58ewdzJxSxYW8Lf/xbs7nj0lN6xtrYlmRMInrIZMPd+elbW/m759YSNaO1K820sjH87VVnMHlcPk8v38mzK3ayZX/bgOPsVpiI0tqV5oLZ4/nX6xZQEty7OZ1xtte3kRePUBCP0dSR5Km3d7Do7R2HfIpLRCNMKsln4th8OlMZmtqT7GvppLkjRSIa4axpJdRsa6C0IMFfffo0TptUzLKtB1hee4AJxXlcs2Aq08oKen5eJvj99n6/PfTmFv7h+XV0JPt+UotHjY+dNpHzZ5fz6vo6Xllfd8iNi0oL4owvymN8YYJxY+IU58fZeaCdNzft589++2S+9NE53PXsWh54fTM/vG4BHzttIo9Ub+d7izfQ1JGkcnwBs8qLKC9OkBfLbotppQV8/kPTD/u7HYyCfhhaO1P89TOrebymloVzxjMmHuO/1u7hS5fM4Q8vnsV3X3iXh97ayvjCPG48fwbXnTeDsiBs9zR18Pa2A6yoPcA7tQdYsb2R5s4UEYOzppVw4wWVfGr+ZKIRw915ZX0d//j8u6zZ1cSZU8fxF5fNY0dDO//2P5tYvydbvz1lYjFXnT2FbfWtPFGzg7Q7BfEozZ0pzGB2RRGV4wupHF+AGbyzvZGVOxppT6YpzovxqTMnccHscrbVt7F+TzNb9rfR1pmirStNVzrDpHH5TC0dQywS4fnVu0mmM3x03gTmTiymIB6lpSvFj9/YQtSM/3PpKfzWKRU4kExnWLKpnudW7mLplnoyfvANub+li5Zg3HMnFDOtbAxTSwuIRYzN+1rZvK+VTftaSUQjXHnWZBrbk/znmj3ccvEszppWwhcfXsYtF8/izstPpTOV5m9+uYaHl2zrs51mVRTyu+dM44ozp7B5Xyv/tXYPL7+7l73NnbR0pnCHj5xSwXc/eybji/JIpTPc/tg7PL18J9GIETXjmg9OZePeFn6zpZ5Pzp/EdedO5+X1dbywejdb97fxL59fwCfnTxrwddKRTPPSur28u6eZDXtaWLurqedCeYlohLOml3DB7PFcMLucqhmlRCJGMp3hY/e8Ql4synO3XUQ0Yvzw5Y3c/fw6AIrzYny2ahpnTB1LY1uSxvYU+1s72d3YwZ6mDgrzYlw4t5yL51ZQXpTH8u0N1GxtoK65k8ryQmZVFLF+dzP3vbKRkoI4cycU8+am/fz5x0/hCx+ezdefXMkvlm7nMwumMCYe5Y2N+3tCtaQgTnlRHoWJKHnxKK2dKVbvbOLikyv4p9+Zz5Z9rXztyZVsqsu2jxgsnFPOhXPKmVleSGV5IePGxOlIpulIZohFjYlj8ynKi/F4TS13LlrJ5JJ87rz8VN7ctJ9nV+yirvnQctKHZpbxqfmTKEjESKYztCfT7G7qYOeBDvY0dpAXjzBuTJySgjjnVJZxybwJFOfHWbWjkTufXMmK2oM3FSrOi9HSlQLgwjnlTC8rYO2uJt7d3YwDZ04tYcGMEqq3NLBkcz0fPrmCb15xOuVF2Vn6tvo2Hlm6nUXLamloS3LS2HwuO+MkLj65gs5khn0tndQ1d7K/tZP9LV3sb+miqSNJc0eKzlSaL35kDjdfOBOArlSGz973Bpv2tXLS2Hw27G3hnMpSzppWkn0/1LXS0NZFVypDVzrDGVPGseiLC48kwo4u6M1sGvAQMBFw4H53/36/NlcCdwEZIAV82d1fC9bdCPxl0PRv3f3Hh3u+0Qr6bo8u3c43nl5FVzrDNz99OjdeUNmzbvn2A3xv8XpeWV9HXizCh2aNZ+PeFnYcaAcgFjHmTSrmzKklLJxTzsLZ5YN+pMxknEVv7+A7L7zL7uDTxLyTivmji2bRnkyzaFkty7YdIBGL8Lmqqdx68WwmjcvnndpGXtuwjzW7Gtmyr42t9a1kMnDa5LGcNa2Ec2dm3wSDzSwHUtfcyUNvbuHR6u3Ut3aRTGdfEx87bSLfuuJ0JpeMGfBxDa1dJNMZyovyegJt+fYD/M/6Otbsaqa2oY3ahnaS6QwzywuZWV7IB6aM43NV06goziOdcb4ZlBciBmdMGcdjX7igzyyztqGNjmQaMBLRCNPKxvTMSgf6nXak0oeUGdIZ5x+fX0cy7fzRxTOZNG4M6Yxz3ysb+d7i9aQyTjxqnD+7nGurpg0a8oOpb+2iZmsDS7fU8+bG/aza2Yg7VI4v4KYLKulKZ/j2c+t44KYqLpk3EcjOnO9/dRMFiSifWTD1kPLTkVizs4mvPPEOq3Y08c1Pn8ZNC2f2PNff/3od97+6icJElHNnlnHOzDJSaaeuuZN9LZ20daVpT6ZJpTNcdfYUrj9vRp9POj9bsg0DPjl/MhXFeYfpRV81W+u59Sc17GvpIhGNcMm8CXzklAoyDm1dKSKWnTn3nnmPVDrjPL18B6m0s2BGCbPKi9jZ2M5j1bU8XlNLU3uSUyeN5dRJxQAs23aANbuaGBOP8lefOo3PVk0d8DXVmUqzvb6NWeVFh5SQRmJ7fRufvvc1SsbE+eplp/Lx0ycO+hp290HXDeVog34SMMndl5lZMVADXOXua3q1KQJa3d3NbD7wqLvPM7MyoBqoIvtHogb4oLsPemrqaAc9wHt7W2ho6+KcXvX6vuubeeD1Lfxmc7Zme/b07F/o0yePHVHAArR3pXlq+Q4ml4zh4rnlfTZybUMbY+LRPrXC/jIZJ+N+SE33aCTTGZLpzCGBeSS6X1+He2H/68sbeax6Oz+++VxmjC886ucciXd3N7N5XysL54w/qn0ZvTW2JXl5/V4efGMLb287AMC5lWU8cut5R/wmHq5UOsOuxo4Bg3N3YwfjiwauLR9P3Z94z589ftCS3vE0UHi2BTP+Y/EaH47mjiRj4tFj+j7t75iWbszsaeBed188yPrzgQfc/VQz+z3gI+5+a7Du/wIvu/vPB/v574egFzlWlm1r4Km3d3D9eTOYO7F4tLsjIXa4oB/RnzMzqwTOBpYMsO5q4O+BCcAng8VTgN7Ht9UGy/o/9hbgFoDp049sR4TI+9GC6aUsmF462t2QHDfszxFBeeYJsvX3pv7r3f1Jd58HXEW2Xj9s7n6/u1e5e1VFRcVIHioiIkMYVtCbWZxsyD/s7osO19bdXwVmmVk5sAOY1mv11GCZiIicIEMGvWX3YvwIWOvu9wzSZk7QDjNbAOQB+4EXgEvNrNTMSoFLg2UiInKCDKdGvxC4HlhpZsuDZXcC0wHc/T7gGuAGM0sC7cC1nt3LW29mdwFLg8f9jbvrFk8iIieQTpgSEQmBwx11k5MXNRMRySUKehGRkFPQi4iE3PuuRm9mdcDWo/gR5UCu3RQ2F8cMuTnuXBwz5Oa4RzrmGe4+4IlI77ugP1pmVj3YDomwysUxQ26OOxfHDLk57mM5ZpVuRERCTkEvIhJyYQz6+0e7A6MgF8cMuTnuXBwz5Oa4j9mYQ1ejFxGRvsI4oxcRkV4U9CIiIReaoDezT5jZu2b2npl9dbT7c7yY2TQze8nM1pjZajO7LVheZmaLzWxD8H/o7nZhZlEze9vMng2+n2lmS4Jt/oiZJUa7j8eamZWY2eNmts7M1prZ+WHf1mb2Z8Fre5WZ/dzM8sO4rc3sATPba2arei0bcNta1g+C8a8IrhI8bKEIejOLAv8CXAacBvyemZ02ur06blLA7e5+GnAe8MfBWL8KvOjuc4EXg+/D5jZgba/v7wa+5+5zgAbgD0alV8fX94Hng5v6nEl2/KHd1mY2BfgSUOXuHwCiwO8Szm39IPCJfssG27aXAXODf7cAPxzJE4Ui6IFzgffcfZO7dwG/AK4c5T4dF+6+y92XBV83k33jTyE73h8HzX5M9k5foWFmU8neovLfg+8NuAR4PGgSxjGPAy4mez8I3L3L3Q8Q8m1N9vLpY8wsBhQAuwjhtg5u0tT/su2DbdsrgYc86y2gxMwmDfe5whL0w7o3bdj0u4fvRHffFazaDUwcrX4dJ/8MfAXIBN+PBw64eyr4PozbfCZQB/xHULL6dzMrJMTb2t13AN8BtpEN+EaghvBv626DbdujyriwBH3OOdw9fIObvoTmuFkz+xSw191rRrsvJ1gMWAD80N3PBlrpV6YJ4bYuJTt7nQlMBgo5tLyRE47ltg1L0OfUvWkHuYfvnu6PcsH/e0erf8fBQuAKM9tCtix3CdnadUnw8R7Cuc1rgVp3XxJ8/zjZ4A/ztv5tYLO717l7ElhEdvuHfVt3G2zbHlXGhSXolwJzgz3zCbI7b54Z5T4dF4e5h+8zwI3B1zcCT5/ovh0v7v41d5/q7pVkt+1/u/t1wEvA7wTNQjVmAHffDWw3s1OCRR8F1hDibU22ZHOemRUEr/XuMYd6W/cy2LZ9huztWs3MzgMae5V4hubuofgHXA6sBzYCXx/t/hzHcV5I9uPcCmB58O9ysjXrF4ENwH8BZaPd1+M0/o8AzwZfzwJ+A7wHPAbkjXb/jsN4zwKqg+39FFAa9m0NfAtYB6wCfgLkhXFbAz8nux8iSfbT2x8Mtm0BI3tk4UZgJdmjkob9XLoEgohIyIWldCMiIoNQ0IuIhJyCXkQk5BT0IiIhp6AXEQk5Bb2ISMgp6EVEQu7/AcalDoyGqAc6AAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's look at the loss history!\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:47<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after training for 100 epochs:  0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check how it performs on validation set\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Now, let's train more and see if it performs better\n",
    "classifier.fit(train_X, train_y, epochs=100, learning_rate=1e-3, batch_size=300, reg=1e1)\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy after training for 100 epochs: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как и раньше, используем кросс-валидацию для подбора гиперпараметтов.\n",
    "\n",
    "В этот раз, чтобы тренировка занимала разумное время, мы будем использовать только одно разделение на тренировочные (training) и проверочные (validation) данные.\n",
    "\n",
    "Теперь нам нужно подобрать не один, а два гиперпараметра! Не ограничивайте себя изначальными значениями в коде.  \n",
    "Добейтесь точности более чем **20%** на проверочных данных (validation data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:18<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_strength = 0.0001\n",
      "learning_rate = 0.001\n",
      "accuracy = 0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [01:30<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_strength = 0.0001\n",
      "learning_rate = 0.0001\n",
      "accuracy = 0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [01:14<00:00,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_strength = 0.0001\n",
      "learning_rate = 1e-05\n",
      "accuracy = 0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [01:14<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_strength = 1e-05\n",
      "learning_rate = 0.001\n",
      "accuracy = 0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [01:20<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_strength = 1e-05\n",
      "learning_rate = 0.0001\n",
      "accuracy = 0.172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [01:16<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_strength = 1e-05\n",
      "learning_rate = 1e-05\n",
      "accuracy = 0.116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [01:13<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_strength = 1e-06\n",
      "learning_rate = 0.001\n",
      "accuracy = 0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [01:14<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_strength = 1e-06\n",
      "learning_rate = 0.0001\n",
      "accuracy = 0.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [01:16<00:00,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_strength = 1e-06\n",
      "learning_rate = 1e-05\n",
      "accuracy = 0.15\n",
      "Best reg_strength = 1e-06\n",
      "Best learning_rate = 0.001\n",
      "Best val_accuracy = 0.228\n",
      "Best validation accuracy: 0.228000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 300\n",
    "\n",
    "learning_rates = [1e-3, 1e-4, 1e-5]\n",
    "reg_strengths = [1e-4, 1e-5, 1e-6]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "for reg_strength in reg_strengths:\n",
    "    for learning_rate in learning_rates:\n",
    "        classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "        classifier.fit(train_X, train_y,\n",
    "                       epochs=num_epochs,\n",
    "                       learning_rate=learning_rate,\n",
    "                       batch_size=batch_size,\n",
    "                       reg=reg_strength)\n",
    "        pred = classifier.predict(val_X)\n",
    "        accuracy = multiclass_accuracy(pred, val_y)\n",
    "\n",
    "        if best_val_accuracy is None or best_val_accuracy < accuracy:\n",
    "            best_val_accuracy = accuracy\n",
    "            best_learning_rate = learning_rate\n",
    "            best_reg_strength = reg_strength\n",
    "            best_classifier = classifier\n",
    "\n",
    "        print('reg_strength =', reg_strength, flush=True)\n",
    "        print('learning_rate =', learning_rate, flush=True)\n",
    "        print('accuracy =', accuracy, flush=True)\n",
    "\n",
    "print('Best reg_strength =', best_reg_strength, flush=True)\n",
    "print('Best learning_rate =', best_learning_rate, flush=True)\n",
    "print('Best val_accuracy =', best_val_accuracy, flush=True)\n",
    "\n",
    "print('Best validation accuracy: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Какой же точности мы добились на тестовых данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear softmax classifier test set accuracy: 0.195000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Linear softmax classifier test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}